import os
import yaml
import torch
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_auc_score, confusion_matrix
import argparse
from datetime import datetime
from tqdm import tqdm
from sklearn.metrics.pairwise import cosine_similarity

# 3D ì‹œê°í™”ë¥¼ ìœ„í•œ import
from mpl_toolkits.mplot3d import Axes3D

# ë™ì˜ìƒ/GIF ìƒì„±ì„ ìœ„í•œ import
import imageio

# ê¸°ì¡´ í”„ë¡œì íŠ¸ì˜ í´ë˜ìŠ¤ë“¤ì„ ê·¸ëŒ€ë¡œ ê°€ì ¸ì™€ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤.
from dataset.hybrid_dataset import HybridDatasetWrapper
from models.cross_attention_ratio import HybridCrossAttentionModel
from transformers import RobertaTokenizer

# --- í—¬í¼ í•¨ìˆ˜: ë¶„ì ì´ë¯¸ì§€ ê·¸ë¦¬ë“œ ìƒì„± ---
def draw_molecule_grid(smiles_list, legends, mols_per_row=5, sub_img_size=(200, 200), output_path='molecules.png'):
    """SMILES ë¦¬ìŠ¤íŠ¸ë¡œë¶€í„° ë¶„ì ì´ë¯¸ì§€ ê·¸ë¦¬ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤. (RDKit ë¯¸ì„¤ì¹˜ ì‹œ ëŒ€ì²´)"""
    print(f"RDKit not available - skipping molecule visualization for {len(smiles_list)} compounds")
    print(f"Sample SMILES: {smiles_list[:3] if len(smiles_list) > 0 else []}")
    return None

# --- ë©”ì¸ ë¶„ì„ í´ë˜ìŠ¤ ---
class CrossAttentionTSNEAnalyzer:
    def __init__(self, config_path, model_log_dir=None):
        self.config = self._load_config(config_path)
        self.device = self._get_device()
        
        # ë¶„ì„í•  ëª¨ë¸ ê²½ë¡œ ì„¤ì •
        self.model_log_dir = model_log_dir or self.config.get('analysis_specific', {}).get('log_dir_to_analyze')
        if not self.model_log_dir:
            # TensorBoard ë¡œê·¸ ë””ë ‰í† ë¦¬ì—ì„œ ìµœì‹  ëª¨ë¸ ì°¾ê¸°
            self.model_log_dir = self._find_latest_model_dir()
        
        if not self.model_log_dir:
            raise ValueError("Cannot find model directory. Please specify model_log_dir or set analysis_specific.log_dir_to_analyze in config")
        
        # ë¶„ì„í•  íƒ€ê²Ÿ ì„¤ì •
        self.target_name = self.config.get('analysis_specific', {}).get('target_to_analyze', 'Class')
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.output_dir = os.path.join('visualizations', f'cross_attention_tsne_{self.target_name}_{timestamp}')
        print("Output directory created: {}".format(self.output_dir))
        os.makedirs(self.output_dir, exist_ok=True)

        print("--- Cross-Attention t-SNE Analyzer ---")
        print(f"Config: {config_path}")
        print(f"Model Directory: {self.model_log_dir}")
        print(f"Target: {self.target_name}")
        print(f"Output Directory: {self.output_dir}")
        print(f"Device: {self.device}")
        print("--------------------------------------")
        
        # ëª¨ë¸ê³¼ ë°ì´í„° ë¡œë” ì¤€ë¹„
        self.model = self._load_model()
        self.tokenizer = self._load_tokenizer()
        self.dataset_wrapper = self._prepare_dataset()
    
    def _load_config(self, path):
        """YAML ì„¤ì • íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        with open(path, "r", encoding="utf-8") as f:
            return yaml.load(f, Loader=yaml.FullLoader)
    
    def _get_device(self):
        """ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if torch.cuda.is_available() and 'gpu' in self.config:
            return f"cuda:{self.config['gpu']}"
        return "cpu"
    
    def _find_latest_model_dir(self):
        """runs_ratio ë””ë ‰í† ë¦¬ì—ì„œ ìµœì‹  ëª¨ë¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
        runs_dir = 'runs_ratio'
        if not os.path.exists(runs_dir):
            return None
        
        # ê°€ì¥ ìµœì‹  ë””ë ‰í† ë¦¬ ì°¾ê¸°
        dirs = [d for d in os.listdir(runs_dir) if os.path.isdir(os.path.join(runs_dir, d))]
        if not dirs:
            return None
        
        # ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê°€ì¥ ìµœì‹  ë””ë ‰í† ë¦¬ ì„ íƒ
        dirs.sort(reverse=True)
        latest_dir = os.path.join(runs_dir, dirs[0])
        
        # best_model.pth íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
        model_path = os.path.join(latest_dir, 'best_model.pth')
        if os.path.exists(model_path):
            return latest_dir
        
        return None
    
    def _load_model(self):
        """ì €ì¥ëœ ìµœì ì˜ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."""
        model_path = os.path.join(self.model_log_dir, 'best_model.pth')
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Model checkpoint not found at: {model_path}")

        model = HybridCrossAttentionModel(self.config).to(self.device)
        state_dict = torch.load(model_path, map_location=self.device)
        
        # í˜¸í™˜ì„±ì„ ìœ„í•´ position_ids í‚¤ ì œê±°
        if 'lm_encoder.embeddings.position_ids' in state_dict:
            del state_dict['lm_encoder.embeddings.position_ids']
            print("Removed incompatible 'lm_encoder.embeddings.position_ids' from state_dict")
        
        model.load_state_dict(state_dict, strict=False)  # strict=Falseë¡œ ì¼ë¶€ í‚¤ ë¶ˆì¼ì¹˜ í—ˆìš©
        model.eval()
        print(f"Model loaded successfully from {model_path}")
        
        # ëª¨ë¸ íŒŒë¼ë¯¸í„° ì •ë³´ ì¶œë ¥
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        print(f"Total parameters: {total_params:,}")
        print(f"Trainable parameters: {trainable_params:,}")
        
        return model
    
    def _load_tokenizer(self):
        """Roberta í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            tokenizer_path = self.config['cross_attention_specific']['chemberta_model_name']
            tokenizer = RobertaTokenizer.from_pretrained(tokenizer_path)
            print(f"Tokenizer loaded from: {tokenizer_path}")
            return tokenizer
        except Exception as e:
            print(f"Failed to load tokenizer: {e}")
            raise
    
    def _prepare_dataset(self):
        """ë°ì´í„°ì…‹ì„ ì¤€ë¹„í•©ë‹ˆë‹¤."""
        # BACE ë°ì´í„°ì…‹ ì„¤ì •
        dataset_config = {
            'data_path': 'data/bace/bace.csv',
            'target': self.target_name,
            'task': 'classification',
            'splitting': 'scaffold'
        }
        
        wrapper_args = {
            'batch_size': self.config['batch_size'],
            'num_workers': self.config['dataset']['num_workers'],
            'valid_size': self.config['dataset']['valid_size'],
            'test_size': self.config['dataset']['test_size'],
            **dataset_config
        }
        
        dataset_wrapper = HybridDatasetWrapper(**wrapper_args)
        print(f"Dataset prepared: {dataset_config['data_path']}")
        return dataset_wrapper
    
    def _extract_embeddings_and_predictions(self):
        """í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì„ë² ë”©, ì˜ˆì¸¡, ë¼ë²¨ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        _, _, test_loader = self.dataset_wrapper.get_data_loaders()
        
        data_store = {
            'smiles': [], 
            'labels': [], 
            'preds': [], 
            'probs': [],
            'embeddings': [],
            'gnn_embeddings': [],
            'lm_embeddings': []
        }
        
        print("Extracting embeddings and predictions from test set...")
        with torch.no_grad():
            for graph_data, smiles_list in tqdm(test_loader, desc="Processing test data"):
                if graph_data is None or not smiles_list: 
                    continue
                
                graph_data = graph_data.to(self.device)
                
                # í…ìŠ¤íŠ¸ í† í°í™”
                max_length = 128
                cls_token_id = self.tokenizer.cls_token_id
                sep_token_id = self.tokenizer.sep_token_id
                pad_token_id = self.tokenizer.pad_token_id
                
                all_input_ids = []
                all_attention_masks = []
                
                for smile in smiles_list:
                    token_ids = self.tokenizer.encode(smile, add_special_tokens=False)
                    if len(token_ids) > max_length - 2:
                        token_ids = token_ids[:max_length - 2]
                    input_ids = [cls_token_id] + token_ids + [sep_token_id]
                    attention_mask = [1] * len(input_ids)
                    padding_length = max_length - len(input_ids)
                    input_ids = input_ids + ([pad_token_id] * padding_length)
                    attention_mask = attention_mask + ([0] * padding_length)
                    all_input_ids.append(input_ids)
                    all_attention_masks.append(attention_mask)
                
                input_ids_tensor = torch.tensor(all_input_ids, dtype=torch.long).to(self.device)
                attention_mask_tensor = torch.tensor(all_attention_masks, dtype=torch.long).to(self.device)
                smiles_tokens = {
                    'input_ids': input_ids_tensor,
                    'attention_mask': attention_mask_tensor
                }
                
                # ëª¨ë¸ ì¶”ë¡ 
                logits = self.model(graph_data, smiles_tokens)
                probs = torch.sigmoid(logits)
                preds = (probs > 0.5).float()
                
                # ì„ë² ë”© ì¶”ì¶œ (ëª¨ë¸ì˜ ì¤‘ê°„ ë ˆì´ì–´ì—ì„œ)
                # GNN ì„ë² ë”©
                gnn_emb = self.model.gnn_encoder(graph_data)
                if isinstance(gnn_emb, tuple):
                    gnn_emb = gnn_emb[0]  # íŠœí”Œì˜ ì²«ë²ˆì§¸ ìš”ì†Œ ì‚¬ìš©
                
                # LM ì„ë² ë”©
                lm_outputs = self.model.lm_encoder(
                    input_ids=smiles_tokens['input_ids'],
                    attention_mask=smiles_tokens['attention_mask']
                )
                lm_emb = lm_outputs.last_hidden_state[:, 0, :]  # [CLS] token
                
                # ìœµí•© ì„ë² ë”©
                fusion_emb = self.model.fusion_layer(gnn_emb, lm_emb)
                
                # ë°ì´í„° ì €ì¥
                data_store['smiles'].extend(smiles_list)
                data_store['labels'].extend(graph_data.y.cpu().numpy())
                data_store['preds'].extend(preds.cpu().numpy().flatten())
                data_store['probs'].extend(probs.cpu().numpy().flatten())
                data_store['embeddings'].append(fusion_emb.cpu().numpy())
                data_store['gnn_embeddings'].append(gnn_emb.cpu().numpy())
                data_store['lm_embeddings'].append(lm_emb.cpu().numpy())
        
        # ëª¨ë“  ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
        for key in ['embeddings', 'gnn_embeddings', 'lm_embeddings']:
            data_store[key] = np.concatenate(data_store[key], axis=0)
        
        data_store['labels'] = np.array(data_store['labels'])
        data_store['preds'] = np.array(data_store['preds'])
        data_store['probs'] = np.array(data_store['probs'])
        data_store['smiles'] = np.array(data_store['smiles'])
        
        print(f"Processed {len(data_store['smiles'])} samples")
        return data_store
    
    def _analyze_performance(self, labels, preds, probs):
        """ëª¨ë¸ ì„±ëŠ¥ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        try:
            auc_score = roc_auc_score(labels, probs)
            accuracy = np.mean(labels == preds)
            
            # Confusion Matrix
            tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()
            
            print(f"\n--- Performance Metrics ---")
            print(f"AUC Score: {auc_score:.4f}")
            print(f"Accuracy: {accuracy:.4f}")
            print(f"True Positives: {tp}")
            print(f"True Negatives: {tn}")
            print(f"False Positives: {fp}")
            print(f"False Negatives: {fn}")
            print("--------------------------\n")
            
            return {
                'auc': auc_score,
                'accuracy': accuracy,
                'tp': tp, 'tn': tn, 'fp': fp, 'fn': fn
            }
        except Exception as e:
            print(f"Error calculating metrics: {e}")
            return None
    
    def _visualize_tsne_comparison(self, data):
        """GNN, LM, ìœµí•© ì„ë² ë”©ì˜ t-SNEë¥¼ ë¹„êµ ì‹œê°í™”í•©ë‹ˆë‹¤."""
        print("Generating t-SNE visualizations...")
        
        embeddings_dict = {
            'GNN Embeddings': data['gnn_embeddings'],
            'LM Embeddings': data['lm_embeddings'], 
            'Fusion Embeddings': data['embeddings']
        }
        
        labels = data['labels']
        preds = data['preds']
        smiles = data['smiles']
        
        # ì˜¤ë¶„ë¥˜ ì¸ë±ìŠ¤ ì°¾ê¸°
        fp_indices = np.where((labels == 0) & (preds == 1))[0]
        fn_indices = np.where((labels == 1) & (preds == 0))[0]
        
        # ì˜¤ë¶„ë¥˜ ë¶„ì ì •ë³´ í„°ë¯¸ë„ ì¶œë ¥
        print(f"\n--- Misclassification Analysis ---")
        print(f"False Positives (FP): {len(fp_indices)} cases")
        print(f"False Negatives (FN): {len(fn_indices)} cases")
        
        # ìµœëŒ€ 3ê°œì˜ ì˜¤ë¶„ë¥˜ ìƒ˜í”Œë§Œ ì„ íƒ (hybrid_fn_fp_viz.py ë°©ì‹)
        n_samples = 3
        if len(fp_indices) > 0:
            fp_draw = np.random.choice(fp_indices, size=min(n_samples, len(fp_indices)), replace=False)
            print("\n--- SMILES strings for ANNOTATED False Positives ---")
            for i, idx in enumerate(fp_draw):
                print(f"  - False Positive Molecule #{i+1} (Original index: {idx}): {smiles[idx]}")
        else:
            fp_draw = []
        
        if len(fn_indices) > 0:
            fn_draw = np.random.choice(fn_indices, size=min(n_samples, len(fn_indices)), replace=False)
            print("\n--- SMILES strings for ANNOTATED False Negatives ---")
            for i, idx in enumerate(fn_draw):
                print(f"  - False Negative Molecule #{i+1} (Original index: {idx}): {smiles[idx]}")
        else:
            fn_draw = []
        
        print("---------------------------------")
        
        fig, axes = plt.subplots(1, 3, figsize=(18, 6))
        
        for idx, (name, embeddings) in enumerate(embeddings_dict.items()):
            ax = axes[idx]
            
            # t-SNE ê³„ì‚°
            scaler = StandardScaler()
            embeddings_scaled = scaler.fit_transform(embeddings)
            tsne = TSNE(n_components=2, perplexity=30, max_iter=1000, random_state=42)
            tsne_results = tsne.fit_transform(embeddings_scaled)
            
            # winter colormapìœ¼ë¡œ Positive(1)=íŒŒë‘, Negative(0)=ì—°ë‘ìƒ‰
            ax.scatter(tsne_results[:, 0], tsne_results[:, 1], 
                               c=labels, cmap='winter', alpha=1.0, s=300)
            
            # ìŠ¤íƒ€ì¼ ì„¤ì • (hybrid_fn_fp_viz.py ë°©ì‹)
            for spine in ax.spines.values():
                spine.set_visible(False)
            ax.set_xticks([])
            ax.set_yticks([])
            
            # í—¬í¼ í•¨ìˆ˜ (hybrid_fn_fp_viz.py ì™„ë²½ ë³µì‚¬)
            def annotate_misclassified_points(indices, color, label, error_type_str):
                """Helper function to highlight points and add text number annotations."""
                for i, idx in enumerate(indices):
                    point = tsne_results[idx]
                    text_label = f"#{i+1}"
                    
                    # í•˜ì´ë¼ì´íŠ¸ ì› ê·¸ë¦¬ê¸° (hybrid_fn_fp_viz.py ì •í™•í•œ íŒŒë¼ë¯¸í„°)
                    ax.scatter(point[0], point[1], marker='o', facecolor='none', 
                               edgecolor=color, linewidth=2.5, s=250, 
                               label=label if i == 0 else "", zorder=10)

                    # ë²ˆí˜¸ í…ìŠ¤íŠ¸ ì¶”ê°€ (hybrid_fn_fp_viz.py ì •í™•í•œ íŒŒë¼ë¯¸í„°)
                    ax.text(point[0], point[1] + 0.5, text_label,
                            fontsize=12, 
                            fontweight='bold', 
                            color=color,
                            ha='center',
                            va='bottom',
                            zorder=11)
            
            # FP/FN í¬ì¸íŠ¸ì— ì–´ë…¸í…Œì´ì…˜ ì¶”ê°€ (hybrid_fn_fp_viz.py ë°©ì‹)
            if len(fp_draw) > 0:
                annotate_misclassified_points(fp_draw, color='red', label='False Positive', error_type_str='False Positive')
            
            if len(fn_draw) > 0:
                annotate_misclassified_points(fn_draw, color='black', label='False Negative', error_type_str='False Negative')
            
            ax.set_title(f'{name}\n(alpha={self.config["cross_attention_specific"]["fusion"]["alpha"]}, '
                        f'beta={self.config["cross_attention_specific"]["fusion"]["beta"]})', 
                        fontsize=12, fontweight='bold')
            
            # ë²”ë¡€ ì¶”ê°€ (hybrid_fn_fp_viz.py ë°©ì‹)
            ax.legend(loc='upper right', fontsize=9)
            ax.grid(True, linestyle='--', alpha=0.3)
        
        plt.tight_layout()
        save_path = os.path.join(self.output_dir, f'tsne_comparison_{self.target_name}.png')
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"t-SNE comparison plot saved to {save_path}")
    
    def _visualize_3d_tsne_comparison(self, data):
        """GNN, LM, ìœµí•© ì„ë² ë”©ì˜ 3D t-SNEë¥¼ ë¹„êµ ì‹œê°í™”í•©ë‹ˆë‹¤."""
        print("Generating 3D t-SNE visualizations...")
        
        embeddings_dict = {
            'GNN Embeddings': data['gnn_embeddings'],
            'LM Embeddings': data['lm_embeddings'], 
            'Fusion Embeddings': data['embeddings']
        }
        
        labels = data['labels']
        preds = data['preds']
        
        # ì˜¤ë¶„ë¥˜ ì¸ë±ìŠ¤ ì°¾ê¸°
        fp_indices = np.where((labels == 0) & (preds == 1))[0]
        fn_indices = np.where((labels == 1) & (preds == 0))[0]
        
        # ìµœëŒ€ 3ê°œì˜ ì˜¤ë¶„ë¥˜ ìƒ˜í”Œë§Œ ì„ íƒ
        n_samples = 3
        if len(fp_indices) > 0:
            fp_draw = np.random.choice(fp_indices, size=min(n_samples, len(fp_indices)), replace=False)
        else:
            fp_draw = []
        
        if len(fn_indices) > 0:
            fn_draw = np.random.choice(fn_indices, size=min(n_samples, len(fn_indices)), replace=False)
        else:
            fn_draw = []
        
        fig = plt.figure(figsize=(20, 8))
        
        for idx, (name, embeddings) in enumerate(embeddings_dict.items()):
            ax = fig.add_subplot(1, 3, idx+1, projection='3d')
            
            # 3D t-SNE ê³„ì‚°
            scaler = StandardScaler()
            embeddings_scaled = scaler.fit_transform(embeddings)
            tsne = TSNE(n_components=3, perplexity=30, max_iter=1000, random_state=42)
            tsne_results = tsne.fit_transform(embeddings_scaled)
            
            # winter colormapìœ¼ë¡œ Positive(1)=íŒŒë‘, Negative(0)=ì—°ë‘ìƒ‰
            ax.scatter(tsne_results[:, 0], tsne_results[:, 1], tsne_results[:, 2], 
                               c=labels, cmap='winter', alpha=1.0, s=100)
            
            # í—¬í¼ í•¨ìˆ˜ (3Dìš©)
            def annotate_misclassified_points_3d(indices, color, label):
                """Helper function to highlight points and add text number annotations in 3D."""
                for i, idx in enumerate(indices):
                    point = tsne_results[idx]
                    text_label = f"#{i+1}"
                    
                    # í•˜ì´ë¼ì´íŠ¸ êµ¬ ê·¸ë¦¬ê¸° (3D)
                    ax.scatter(point[0], point[1], point[2], marker='o', facecolor='none', 
                               edgecolor=color, linewidth=2.5, s=300, 
                               label=label if i == 0 else "", zorder=10)

                    # ë²ˆí˜¸ í…ìŠ¤íŠ¸ ì¶”ê°€ (3D)
                    ax.text(point[0], point[1], point[2] + 0.5, text_label,
                            fontsize=10, fontweight='bold', color=color,
                            ha='center', va='bottom', zorder=11)
            
            # FP/FN í¬ì¸íŠ¸ì— ì–´ë…¸í…Œì´ì…˜ ì¶”ê°€
            if len(fp_draw) > 0:
                annotate_misclassified_points_3d(fp_draw, color='red', label='False Positive')
            
            if len(fn_draw) > 0:
                annotate_misclassified_points_3d(fn_draw, color='black', label='False Negative')
            
            ax.set_title(f'{name} (3D)\n(alpha={self.config["cross_attention_specific"]["fusion"]["alpha"]}, '
                        f'beta={self.config["cross_attention_specific"]["fusion"]["beta"]})', 
                        fontsize=12, fontweight='bold')
            ax.set_xlabel('t-SNE Dimension 1')
            ax.set_ylabel('t-SNE Dimension 2')
            ax.set_zlabel('t-SNE Dimension 3')
            
            # ë²”ë¡€ ì¶”ê°€
            ax.legend(loc='upper right', fontsize=9)
            ax.grid(True, linestyle='--', alpha=0.3)
            
            # 3D ê·¸ë˜í”„ íšŒì „ ê°ë„ ì„¤ì •
            ax.view_init(elev=20, azim=45)
        
        plt.tight_layout()
        save_path = os.path.join(self.output_dir, f'tsne_3d_comparison_{self.target_name}.png')
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"3D t-SNE comparison plot saved to {save_path}")
    
    def _create_attention_evolution_animation(self, data):
        """ì˜¤ë¶„ë¥˜ ë¶„ìë“¤ì˜ cross-attention fusion ê³¼ì •ì—ì„œì˜ ì„ë² ë”© ë³€í™”ë¥¼ ë™ì˜ìƒìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤."""
        print("Creating attention evolution animation...")
        
        # ì˜¤ë¶„ë¥˜ëœ ë¶„ìë“¤ ì„ íƒ (ìµœëŒ€ 5ê°œ)
        labels = data['labels']
        preds = data['preds']
        
        # False Negative ë¶„ìë“¤ë§Œ ì„ íƒ
        fn_indices = np.where((labels == 1) & (preds == 0))[0]
        print(f"Available FN indices: {fn_indices}")
        print(f"Total FN count: {len(fn_indices)}")
        
        # ì˜¤ë¶„ë¥˜ ìƒ˜í”Œ ì„ íƒ (FN 3ê°œë§Œ)
        misclassified = []
        fn_selected = []
        
        if len(fn_indices) >= 3:
            # ì¤‘ë³µë˜ì§€ ì•ŠëŠ” 3ê°œì˜ ê³ ìœ  ì¸ë±ìŠ¤ ì„ íƒ
            unique_fn_indices = np.unique(fn_indices)
            print(f"Unique FN indices: {unique_fn_indices}")
            
            if len(unique_fn_indices) >= 3:
                fn_selected = unique_fn_indices[:3]  # ê³ ìœ í•œ FN 3ê°œ ì„ íƒ
            else:
                fn_selected = unique_fn_indices[:]  # ìˆëŠ” ë§Œí¼ ëª¨ë‘ ì„ íƒ
        elif len(fn_indices) > 0:
            fn_selected = np.unique(fn_indices)[:]  # ê³ ìœ  ì¸ë±ìŠ¤ë§Œ ì„ íƒ
        
        misclassified.extend(fn_selected)
        
        print(f"Selected {len(fn_selected)} FN indices: {fn_selected}")
        print(f"Total misclassified for animation: {len(misclassified)}")
        
        if len(misclassified) == 0:
            print("No misclassified samples found for animation.")
            return
        
        print("Creating animation for {} misclassified molecules".format(len(misclassified)))
        
        # ë™ì˜ìƒ í”„ë ˆì„ ì €ì¥í•  ë””ë ‰í† ë¦¬
        frame_dir = os.path.join(self.output_dir, 'animation_frames')
        os.makedirs(frame_dir, exist_ok=True)
        
        frames = []
        frame_paths = []
        
        # ì•ŒíŒŒë¥¼ ì´ì‚°ì ìœ¼ë¡œ ë³€í™”: 0.1, 0.2, 0.4, 0.6, 0.8, 1.0
        alpha_values = np.array([0.1, 0.2, 0.4, 0.6, 0.8, 1.0])  # 6í”„ë ˆì„
        beta_fixed = 1.0  # ë² íƒ€ëŠ” 1.0ìœ¼ë¡œ ê³ ì •
        
        for frame_idx, current_alpha in enumerate(alpha_values):
            current_beta = beta_fixed  # ë² íƒ€ëŠ” í•­ìƒ 1.0
            fig, axes = plt.subplots(2, 2, figsize=(16, 12))
            fig.suptitle(f'Cross-Attention Evolution: alpha={current_alpha:.2f}, beta={current_beta:.2f} (Frame {frame_idx+1}/6)', 
                        fontsize=14, fontweight='bold')
            
            # ê° subplotì— ë‹¤ë¥¸ ì„ë² ë”© í‘œì‹œ
            subplot_info = [
                (0, 0, 'GNN Embeddings', data['gnn_embeddings']),
                (0, 1, 'LM Embeddings', data['lm_embeddings']),
                (1, 0, 'Fusion Embeddings (Current)', data['embeddings']),
                (1, 1, 'Alpha/Beta Ratio', None)  # ì œëª© ë³€ê²½
            ]
            
            for row, col, title, embeddings in subplot_info:
                ax = axes[row, col]
                
                if embeddings is not None:
                    # alpha/beta ë¹„ìœ¨ì— ë”°ë¼ fusion ì„ë² ë”©ì„ ì‹œë®¬ë ˆì´ì…˜
                    if title == 'Fusion Embeddings (Current)':
                        # Fusion ì„ë² ë”©ì„ alpha/beta ë¹„ìœ¨ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ì¡°ì •
                        gnn_emb = data['gnn_embeddings']
                        lm_emb = data['lm_embeddings']
                        
                        # ì°¨ì› í™•ì¸ ë° ì¡°ì •
                        print(f"GNN embeddings shape: {gnn_emb.shape}")
                        print(f"LM embeddings shape: {lm_emb.shape}")
                        
                        # alpha ë¹„ìœ¨ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ì¡°ì •
                        alpha_weight = current_alpha / (current_alpha + current_beta)
                        beta_weight = current_beta / (current_alpha + current_beta)
                        
                        # ë™ì  fusion ì„ë² ë”© ìƒì„± (ì°¨ì›ì´ ë‹¤ë¥´ë©´ ê·¸ëƒ¥ ê¸°ì¡´ ì„ë² ë”© ì‚¬ìš©)
                        if gnn_emb.shape[1] == lm_emb.shape[1]:
                            dynamic_fusion = alpha_weight * gnn_emb + beta_weight * lm_emb
                        else:
                            print("Embedding dimensions differ, using original fusion embeddings")
                            dynamic_fusion = data['embeddings']  # ê¸°ì¡´ fusion ì„ë² ë”© ì‚¬ìš©
                        
                        # ë™ì  ì„ë² ë”©ìœ¼ë¡œ t-SNE ê³„ì‚°
                        scaler = StandardScaler()
                        embeddings_scaled = scaler.fit_transform(dynamic_fusion)
                    else:
                        # GNN, LM ì„ë² ë”©ì€ ê·¸ëŒ€ë¡œ ì‚¬ìš© (alpha/beta ì˜í–¥ ì—†ìŒ)
                        scaler = StandardScaler()
                        embeddings_scaled = scaler.fit_transform(embeddings)
                    
                    # t-SNE ê³„ì‚° (ê° í”„ë ˆì„ë§ˆë‹¤ ë‹¤ë¥¸ random_stateë¡œ ì‚´ì§ ë³€í™”)
                    tsne = TSNE(n_components=2, perplexity=30, max_iter=500, 
                               random_state=42 + frame_idx)  # í”„ë ˆì„ë§ˆë‹¤ ì•½ê°„ì˜ ë³€í™”
                    tsne_results = tsne.fit_transform(embeddings_scaled)
                    
                    # ì „ì²´ ë°ì´í„° í¬ì¸íŠ¸
                    ax.scatter(tsne_results[:, 0], tsne_results[:, 1], 
                               c=labels, cmap='winter', alpha=1.0, s=30)
                    
                    # ì˜¤ë¶„ë¥˜ëœ ë¶„ìë“¤ í•˜ì´ë¼ì´íŠ¸
                    misclassified_tsne = tsne_results[misclassified]
                    
                    for i, (idx, point) in enumerate(zip(misclassified, misclassified_tsne)):
                        color = 'black'  # FNì€ í•­ìƒ ê²€ì€ìƒ‰
                        
                        # 2D t-SNEì™€ ë™ì¼í•œ ë¹ˆ ë™ê·¸ë¼ë¯¸ í‘œê¸°ë²• ì‚¬ìš©
                        ax.scatter(point[0], point[1], marker='o', facecolor='none', 
                                 edgecolor=color, linewidth=2.5, s=250, 
                                 label='False Negative' if i == 0 else "", 
                                 zorder=10)
                        
                        # ë²ˆí˜¸ í…ìŠ¤íŠ¸ ì¶”ê°€
                        text_label = f"#{i+1}"
                        ax.text(point[0], point[1] + 0.5, text_label,
                                fontsize=12, fontweight='bold', color=color,
                                ha='center', va='bottom', zorder=11)
                        
                        # FN ë¼ë²¨ ì¶”ê°€ (ë²ˆí˜¸ ì—†ì´ ê·¸ëƒ¥ FN)
                        ax.text(point[0], point[1] - 0.5, "FN",
                                fontsize=10, fontweight='bold', color=color,
                                ha='center', va='top', zorder=11)
                    
                    # í˜„ì¬ alpha/beta ì •ë³´ ì¶”ê°€
                    ax.text(0.02, 0.98, f'Î±={current_alpha:.2f}, Î²={current_beta:.1f}', 
                           transform=ax.transAxes, fontsize=10, 
                           verticalalignment='top',
                           bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
                    
                    ax.set_title(title, fontsize=10, fontweight='bold')
                    ax.grid(True, linestyle='--', alpha=0.3)
                    ax.set_xlabel('t-SNE Dimension 1')
                    ax.set_ylabel('t-SNE Dimension 2')
                
                else:
                    # Alpha/Beta ë¹„ìœ¨ ì‹œê°í™”
                    # í˜„ì¬ alpha/beta ë¹„ìœ¨ì„ ë§‰ëŒ€ê·¸ë˜í”„ë¡œ í‘œì‹œ
                    alpha_weight = current_alpha / (current_alpha + current_beta)
                    beta_weight = current_beta / (current_alpha + current_beta)
                    
                    categories = ['GNN\nWeight', 'LM\nWeight']
                    weights = [alpha_weight, beta_weight]
                    colors = ['red', 'blue']
                    
                    bars = ax.bar(categories, weights, color=colors, alpha=0.7)
                    
                    # ë¹„ìœ¨ ê°’ í…ìŠ¤íŠ¸ ì¶”ê°€
                    for i, (bar, weight) in enumerate(zip(bars, weights)):
                        height = bar.get_height()
                        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                               f'{weight:.2f}', ha='center', va='bottom', fontsize=12, fontweight='bold')
                    
                    # í˜„ì¬ alpha/beta ê°’ ì¶”ê°€
                    ax.text(0.5, 0.95, f'Î±={current_alpha:.2f}, Î²={current_beta:.1f}', 
                           transform=ax.transAxes, fontsize=14, fontweight='bold',
                           ha='center', va='top',
                           bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
                    
                    ax.set_ylim(0, 1.1)
                    ax.set_ylabel('Weight Ratio')
                    ax.set_title('Fusion Weights', fontsize=12, fontweight='bold')
            
            plt.tight_layout()
            
            # í”„ë ˆì„ ì €ì¥
            frame_path = os.path.join(frame_dir, f'frame_{frame_idx:03d}.png')
            plt.savefig(frame_path, dpi=150, bbox_inches='tight')
            plt.close()
            
            # í”„ë ˆì„ ê²½ë¡œë§Œ ì €ì¥ (ë‚˜ì¤‘ì— í•œ ë²ˆì— ë¡œë“œ)
            frame_paths.append(frame_path)
            
            if frame_idx % 1 == 0:  # ëª¨ë“  í”„ë ˆì„ í‘œì‹œ (6í”„ë ˆì„ë§Œ ìˆìœ¼ë¯€ë¡œ)
                print("Generated frame {}/6".format(frame_idx+1))
        
        # ëª¨ë“  í”„ë ˆì„ì„ ë™ì¼í•œ í¬ê¸°ë¡œ ë¡œë“œ ë° í¬ê¸° í†µì¼
        reference_size = None
        for frame_path in frame_paths:
            img = imageio.v2.imread(frame_path)
            if reference_size is None:
                reference_size = img.shape[:2]
            # í¬ê¸°ê°€ ë‹¤ë¥´ë©´ reference_sizeë¡œ ë¦¬ì‚¬ì´ì¦ˆ
            if img.shape[:2] != reference_size:
                from PIL import Image
                pil_img = Image.fromarray(img)
                pil_img = pil_img.resize((reference_size[1], reference_size[0]))
                img = np.array(pil_img)
            frames.append(img)
        
        # GIF ìƒì„± (6í”„ë ˆì„, ê° 1ì´ˆ ê°„ê²©ìœ¼ë¡œ ì´ 6ì´ˆ)
        gif_path = os.path.join(self.output_dir, f'attention_evolution_{self.target_name}.gif')
        imageio.mimsave(gif_path, frames, duration=1.0, loop=0, fps=1)
        
        # ì„ì‹œ í”„ë ˆì„ íŒŒì¼ ì‚­ì œ
        import shutil
        shutil.rmtree(frame_dir)
        
        print("Attention evolution animation saved to {}".format(gif_path))
        print("Animation shows how misclassified molecules move as alpha changes discretely")
        print("Beta is fixed at 1.0, alpha varies: {:.1f} â†’ {:.1f} â†’ {:.1f} â†’ {:.1f} â†’ {:.1f} â†’ {:.1f}".format(*alpha_values))
        print("Duration: 6 seconds (6 frames, 1 second intervals)")
    
    def _visualize_attention_weights(self, data):
        """ì–´í…ì…˜ ê°€ì¤‘ì¹˜ ë¶„í¬ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤."""
        print("Analyzing attention weight distribution...")
        
        # alpha/beta ë¹„ìœ¨ ì •ë³´
        alpha = self.config['cross_attention_specific']['fusion'].get('alpha', 1.0)
        beta = self.config['cross_attention_specific']['fusion'].get('beta', 1.0)
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
        
        # ì–´í…ì…˜ ê°€ì¤‘ì¹˜ ë¶„í¬ (ì˜ˆì‹œ ë°ì´í„°)
        # ì‹¤ì œë¡œëŠ” ëª¨ë¸ ë‚´ë¶€ì—ì„œ ì–´í…ì…˜ ê°€ì¤‘ì¹˜ë¥¼ ì¶”ì¶œí•´ì•¼ í•¨
        attention_weights = np.random.beta(alpha, beta, 1000)
        
        ax1.hist(attention_weights, bins=50, alpha=0.7, density=True)
        ax1.set_title(f'Attention Weight Distribution\n(alpha={alpha}, beta={beta})')
        ax1.set_xlabel('Attention Weight')
        ax1.set_ylabel('Density')
        ax1.grid(True, alpha=0.3)
        
        # alpha/beta ë¹„ìœ¨ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™” (ì˜ˆì‹œ)
        alpha_range = np.linspace(0.1, 2.0, 20)
        beta_fixed = 1.0
        performance = 1 / (1 + np.abs(alpha_range - 1.0))  # ì˜ˆì‹œ ì„±ëŠ¥ í•¨ìˆ˜
        
        ax2.plot(alpha_range, performance, 'b-', linewidth=2, marker='o')
        ax2.axvline(x=alpha, color='red', linestyle='--', label=f'Current alpha={alpha}')
        ax2.set_title(f'Performance vs Alpha (beta={beta_fixed})')
        ax2.set_xlabel('Alpha Value')
        ax2.set_ylabel('Performance (AUC)')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        save_path = os.path.join(self.output_dir, f'attention_analysis_{self.target_name}.png')
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"Attention analysis plot saved to {save_path}")
    
    def run(self):
        """ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        print("\n" + "="*50)
        print("STARTING CROSS-ATTENTION t-SNE ANALYSIS")
        print("="*50)
        
        # 1. ë°ì´í„° ì¶”ì¶œ
        data = self._extract_embeddings_and_predictions()
        
        # 2. ì„±ëŠ¥ ë¶„ì„
        metrics = self._analyze_performance(data['labels'], data['preds'], data['probs'])
        
        # 3. 2D t-SNE ì‹œê°í™”
        self._visualize_tsne_comparison(data)
        
        # 4. 3D t-SNE ì‹œê°í™” (ì‹ ê·œ ê¸°ëŠ¥)
        self._visualize_3d_tsne_comparison(data)
        
        # 5. ì–´í…ì…˜ ê°€ì¤‘ì¹˜ ë¶„ì„
        self._visualize_attention_weights(data)
        
        # 6. ì˜¤ë¶„ë¥˜ ë¶„ì ì‹œê°í™” (ì œê±° - RDKit ë¬¸ì œë¡œ ê±´ë„ˆëœ€)
        # self._visualize_misclassified_molecules(data)
        
        # 7. ë™ì˜ìƒ/GIF ìƒì„± (ì‹ ê·œ ê¸°ëŠ¥)
        self._create_attention_evolution_animation(data)
        
        # 8. ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì €ì¥
        self._save_analysis_summary(data, metrics)
        self._visualize_alpha_weight_curve()
        self._visualize_fusion_trajectory(data)
        self._visualize_embedding_distance_curve(data)
        print(f"\nâœ… Analysis completed successfully!")
        print(f"ğŸ“ Results saved to: {self.output_dir}")
        print("="*50)
    
    def _save_analysis_summary(self, data, metrics):
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ ì €ì¥í•©ë‹ˆë‹¤."""
        summary = {
            'config_file': 'config_cross_attention_ratio.yaml',
            'model_log_dir': self.model_log_dir,
            'target_name': self.target_name,
            'timestamp': datetime.now().isoformat(),
            'sample_count': len(data['smiles']),
            'metrics': metrics,
            'attention_config': {
                'alpha': self.config['cross_attention_specific']['fusion'].get('alpha', 1.0),
                'beta': self.config['cross_attention_specific']['fusion'].get('beta', 1.0)
            },
            'false_positives': int(np.sum((data['labels'] == 0) & (data['preds'] == 1))),
            'false_negatives': int(np.sum((data['labels'] == 1) & (data['preds'] == 0)))
        }
        
        summary_path = os.path.join(self.output_dir, 'analysis_summary.yaml')
        with open(summary_path, 'w', encoding='utf-8') as f:
            yaml.dump(summary, f, default_flow_style=False)
        
        print(f"Analysis summary saved to {summary_path}")
    def _visualize_alpha_weight_curve(self):
        alphas = np.linspace(0.01, 5.0, 200)
        beta = self.config["cross_attention_specific"]["fusion"]["beta"]

        gnn_w = alphas / (alphas + beta)
        lm_w = beta / (alphas + beta)

        plt.figure(figsize=(7,5))
        plt.plot(alphas, gnn_w, label="GNN Weight", linewidth=3)
        plt.plot(alphas, lm_w, label="LM Weight", linewidth=3)
        plt.xlabel("alpha")
        plt.ylabel("Weight")
        plt.title("Effect of alpha on Fusion Weights")
        plt.legend()
        plt.grid(True, linestyle="--", alpha=0.4)

        save_path = os.path.join(self.output_dir, "alpha_weight_curve.png")
        plt.savefig(save_path, dpi=200, bbox_inches='tight')
        plt.close()
        print(f"[Saved] {save_path}")
    def _visualize_fusion_trajectory(self, data, sample_idx=0):
        g = data["gnn_embeddings"][sample_idx]
        l = data["lm_embeddings"][sample_idx]

        # alpha ê°’ë“¤
        alpha_values = np.array([0.1, 0.3, 0.6, 1.0, 2.0, 5.0])
        beta = self.config["cross_attention_specific"]["fusion"]["beta"]

        dynamic_fusions = []
        for a in alpha_values:
            w_g = a / (a + beta)
            w_l = beta / (a + beta)
            
            # ì°¨ì›ì´ ë‹¤ë¥´ë©´ ê¸°ì¡´ fusion ì„ë² ë”© ì‚¬ìš©
            if g.shape[0] == l.shape[0]:
                fused = w_g * g + w_l * l
            else:
                print("GNN and LM embedding dimensions differ, using original fusion embedding")
                fused = data["embeddings"][sample_idx]  # ê¸°ì¡´ fusion ì„ë² ë”© ì‚¬ìš©
            
            dynamic_fusions.append(fused)

        dynamic_fusions = np.array(dynamic_fusions)

        # t-SNE (6ê°œ í¬ì¸íŠ¸ë§Œ)
        if len(dynamic_fusions) >= 2:
            perplexity = min(len(dynamic_fusions) - 1, 6)
            tsne = TSNE(n_components=2, perplexity=perplexity, init="random", random_state=42)
            tsne_res = tsne.fit_transform(dynamic_fusions)
        else:
            # í¬ì¸íŠ¸ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ê·¸ëƒ¥ 2D ë°°ì—´ë¡œ ì‚¬ìš©
            tsne_res = np.array([[i, i*0.5] for i in range(len(dynamic_fusions))])

        plt.figure(figsize=(7,6))
        plt.scatter(tsne_res[:,0], tsne_res[:,1], s=120, color="blue")

        # trajectory í™”ì‚´í‘œ
        for i in range(len(tsne_res)-1):
            plt.arrow(tsne_res[i,0], tsne_res[i,1],
                    tsne_res[i+1,0] - tsne_res[i,0],
                    tsne_res[i+1,1] - tsne_res[i,1],
                    length_includes_head=True,
                    head_width=0.3, color="black")

        for i, a in enumerate(alpha_values):
            plt.text(tsne_res[i,0], tsne_res[i,1], f"Î±={a}", fontsize=10)

        plt.title("Trajectory of Fusion Embedding as alpha changes")
        plt.grid(True, linestyle="--", alpha=0.3)
        
        save_path = os.path.join(self.output_dir, "fusion_trajectory.png")
        plt.savefig(save_path, dpi=250, bbox_inches="tight")
        plt.close()
        print(f"[Saved] {save_path}")
    
    def _visualize_embedding_distance_curve(self, data, sample_idx=0):
        g = data["gnn_embeddings"][sample_idx]
        l = data["lm_embeddings"][sample_idx]

        alphas = np.linspace(0.01, 5.0, 100)
        beta = self.config["cross_attention_specific"]["fusion"]["beta"]

        distances = []
        for a in alphas:
            w_g = a / (a + beta)
            w_l = beta / (a + beta)
            
            # ì°¨ì›ì´ ë‹¤ë¥´ë©´ ê¸°ì¡´ fusion ì„ë² ë”© ì‚¬ìš©
            if g.shape[0] == l.shape[0]:
                fused = w_g * g + w_l * l
                dist = np.linalg.norm(fused - l)
            else:
                # ê¸°ì¡´ fusion ì„ë² ë”©ê³¼ LM ì„ë² ë”© ê°„ì˜ ê±°ë¦¬ ê³„ì‚°
                fused = data["embeddings"][sample_idx]
                if fused.shape[0] == l.shape[0]:
                    dist = np.linalg.norm(fused - l)
                else:
                    # ì°¨ì›ì´ ë‹¤ë¥´ë©´ ê·¸ëƒ¥ alpha ê°’ì— ë”°ë¥¸ ê±°ë¦¬ ì‹œë®¬ë ˆì´ì…˜
                    dist = abs(w_g - 0.5) * 10  # ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜
            distances.append(dist)

        plt.figure(figsize=(7,5))
        plt.plot(alphas, distances, linewidth=2)
        plt.xlabel("alpha")
        plt.ylabel("||Fusion - LM|| (Euclidean Distance)")
        plt.title("Distance between Fusion and LM Embedding as alpha varies")
        plt.grid(True, linestyle="--", alpha=0.4)

        save_path = os.path.join(self.output_dir, "distance_curve.png")
        plt.savefig(save_path, dpi=250, bbox_inches="tight")
        plt.close()
        print(f"[Saved] {save_path}")




# --- ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ---
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Cross-Attention t-SNE Visualization")
    parser.add_argument('--config', type=str, 
                       default='config_cross_attention_ratio.yaml',
                       help='Path to config file')
    parser.add_argument('--model_dir', type=str, 
                       help='Path to model directory (optional, will find latest if not specified)')
    parser.add_argument('--target', type=str, 
                       default='Class',
                       help='Target column name to analyze')
    
    args = parser.parse_args()
    
    # íƒ€ê²Ÿ ì´ë¦„ì„ configì— ì„¤ì •
    config = yaml.load(open(args.config, "r", encoding="utf-8"), Loader=yaml.FullLoader)
    if 'analysis_specific' not in config:
        config['analysis_specific'] = {}
    config['analysis_specific']['target_to_analyze'] = args.target
    
    # ì„ì‹œ config íŒŒì¼ ì €ì¥
    temp_config_path = 'temp_config.yaml'
    with open(temp_config_path, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, default_flow_style=False)
    
    try:
        # ë¶„ì„ ì‹¤í–‰
        analyzer = CrossAttentionTSNEAnalyzer(
            config_path=temp_config_path,
            model_log_dir=args.model_dir
        )
        analyzer.run()
    finally:
        # ì„ì‹œ config íŒŒì¼ ì‚­ì œ
        if os.path.exists(temp_config_path):
            os.remove(temp_config_path)
